{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a344bcb-c47e-419a-808f-418b2c2188f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4235f4-efc5-4a65-b183-2b5551b779c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.1.1-cp39-cp39-win_amd64.whl (10.8 MB)\n",
      "     ---------------------------------------- 10.8/10.8 MB 5.2 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-1.26.0-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 15.8/15.8 MB 4.2 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "     -------------------------------------- 502.5/502.5 KB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\documents\\school\\fallgrad2023\\dw\\datawarehouse_projectreport\\datawarehouse\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\documents\\school\\fallgrad2023\\dw\\datawarehouse_projectreport\\datawarehouse\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.0 pandas-2.1.1 pytz-2023.3.post1 tzdata-2023.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\datawarehouse\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install fuzzywuzzy\n",
    "#!pip install python-Levenshtein\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec8c827-7f78-48d4-abac-3627a093a3bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package            Version\n",
      "------------------ ------------\n",
      "asttokens          2.4.0\n",
      "backcall           0.2.0\n",
      "colorama           0.4.6\n",
      "comm               0.1.4\n",
      "debugpy            1.8.0\n",
      "decorator          5.1.1\n",
      "exceptiongroup     1.1.3\n",
      "executing          2.0.0\n",
      "fuzzywuzzy         0.18.0\n",
      "importlib-metadata 6.8.0\n",
      "ipykernel          6.25.2\n",
      "ipython            8.16.1\n",
      "jedi               0.19.1\n",
      "jupyter_client     8.3.1\n",
      "jupyter_core       5.3.2\n",
      "Levenshtein        0.22.0\n",
      "matplotlib-inline  0.1.6\n",
      "nest-asyncio       1.5.8\n",
      "numpy              1.26.0\n",
      "packaging          23.2\n",
      "pandas             2.1.1\n",
      "parso              0.8.3\n",
      "pickleshare        0.7.5\n",
      "pip                22.0.4\n",
      "platformdirs       3.11.0\n",
      "prompt-toolkit     3.0.39\n",
      "psutil             5.9.5\n",
      "pure-eval          0.2.2\n",
      "Pygments           2.16.1\n",
      "python-dateutil    2.8.2\n",
      "python-Levenshtein 0.22.0\n",
      "pytz               2023.3.post1\n",
      "pywin32            306\n",
      "pyzmq              25.1.1\n",
      "rapidfuzz          3.3.1\n",
      "setuptools         58.1.0\n",
      "six                1.16.0\n",
      "stack-data         0.6.3\n",
      "tornado            6.3.3\n",
      "traitlets          5.11.2\n",
      "typing_extensions  4.8.0\n",
      "tzdata             2023.3\n",
      "wcwidth            0.2.8\n",
      "zipp               3.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\datawarehouse\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3395f778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4498a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max.rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56839cb-e6f6-4c8e-a9d6-8c98599384e7",
   "metadata": {},
   "source": [
    "## Read in CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b368c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colleges123 = pd.read_csv(r\"C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\data\\DatawarehouseProject - colleges123.csv\")\n",
    "colleges123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4559f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_2 = pd.read_csv(r\"C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\data\\DatawarehouseProject - ds1_2.csv\")\n",
    "df1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d54e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(r\"C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\data\\DatawarehouseProject - ds3.csv\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c6bdf-fa48-4afe-b435-d5f16c0a2949",
   "metadata": {},
   "source": [
    "# Clean df1_2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e13dba-610c-4b89-8918-f4266b1098de",
   "metadata": {},
   "source": [
    "## 'Name' Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a467db3",
   "metadata": {},
   "source": [
    "#### Find duplicates in the 'Name' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e2907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# duplicates = df1_2[df1_2.duplicated(subset=['ID', 'Name'], keep=False)]\n",
    "name_duplicates = df1_2[df1_2.duplicated('Name', keep=False)]\n",
    "name_duplicates\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a23a2",
   "metadata": {},
   "source": [
    "Count hopw many duplicates were found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab08269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55147f",
   "metadata": {},
   "source": [
    "These duplicates are indetermanable without more information.\n",
    "Indeterminable factors: \n",
    "    Different Status'\n",
    "We will save them to a new csv file named deleted_name_duplicates to inquire about the records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_duplicates.to_csv(r'C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\data\\deleted_name_duplicates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db33efc1",
   "metadata": {},
   "source": [
    "Now we drop the 'Name' duplicates from the original d1_2 dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286db081",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_2 = df1_2.drop_duplicates(subset='Name', keep=False)\n",
    "df1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf41af-196d-4398-b959-5009ecdf3ac3",
   "metadata": {},
   "source": [
    "## 'ID' Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255652df",
   "metadata": {},
   "source": [
    "### Find duplicates in the 'ID' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad16036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2[df1_2.duplicated('ID', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd4e42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# duplicates = df1_2[df1_2.duplicated(subset=['ID', 'Name'], keep=False)]\n",
    "# id_duplicates = df1_2[df1_2.duplicated('ID', keep = False)]\n",
    "id_duplicates = df1_2[df1_2.duplicated('ID', keep = 'first')]\n",
    "id_duplicates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69b385",
   "metadata": {},
   "source": [
    "For duplicates found in the column ID, generate 3-digit numbers to replace each duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in id_duplicates.iterrows():\n",
    "    new_id = np.random.randint(100, 1000)  # Generate a random 3-digit number\n",
    "    while new_id in df1_2['ID'].values:  # Ensure uniqueness against entire 'ID' column\n",
    "        new_id = np.random.randint(100, 1000)\n",
    "    df1_2.at[index, 'ID'] = new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40cb3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1958c-7e70-4394-815f-5f1ac6e4ba72",
   "metadata": {},
   "source": [
    "## 'Address' Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62a954",
   "metadata": {},
   "source": [
    "#### Check the address column for spelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2853275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_2['Address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_spelling(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.correct()\n",
    "\n",
    "df1_2['Corrected_Address'] = df1_2['Address'].apply(check_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2['Address_Match'] = df1_2['Address'] == df1_2['Corrected_Address']\n",
    "df1_2['Address_Match']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8223bff-33d3-4966-9792-da863f47729c",
   "metadata": {},
   "source": [
    "## 'Major' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49fb9a-a01c-40ed-9fd2-7e57d3e693c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_2['Major']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413121b-2e4b-45dd-8c55-c94508dcd936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of valid majors\n",
    "valid_majors = colleges123['Major'].tolist()\n",
    "# Create a boolean mask to check if 'Major' is in the list of valid majors\n",
    "mask = ~df1_2['Major'].isin(valid_majors)\n",
    "\n",
    "# Filter the DataFrame to display rows where 'Major' doesn't match valid majors\n",
    "rows_with_invalid_majors = df1_2[mask]\n",
    "rows_with_invalid_majors['Major']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12e613-f1c5-491c-92fb-098dcf607144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datawarehouse",
   "language": "python",
   "name": "datawarehouse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
