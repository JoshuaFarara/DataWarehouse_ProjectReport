{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9446a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} - m pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa879ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395f778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4498a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max.rows', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b368c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colleges1_2 = pd.read_csv(r\"C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\data\\DatawarehouseProject - colleges1_2.csv\")\n",
    "colleges1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2 = pd.read_csv(r\"C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\data\\DatawarehouseProject - ds1_2.csv\")\n",
    "df1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fef07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colleges3 = pd.read_csv(r\"C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\data\\DatawarehouseProject - colleges3.csv\")\n",
    "colleges3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(r\"C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\data\\DatawarehouseProject - ds3.csv\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a467db3",
   "metadata": {},
   "source": [
    "Find duplicates in the 'Name' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e2907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# duplicates = df1_2[df1_2.duplicated(subset=['ID', 'Name'], keep=False)]\n",
    "name_duplicates = df1_2[df1_2.duplicated('Name', keep=False)]\n",
    "name_duplicates\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a23a2",
   "metadata": {},
   "source": [
    "Count hopw many duplicates were found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab08269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55147f",
   "metadata": {},
   "source": [
    "These duplicates are indetermanable without more information. We will save them to a new csv file named deleted_name_duplicates to inquire about the records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_duplicates.to_csv(r'C:\\Users\\User\\Documents\\School\\FallGrad2023\\DW\\DataWarehouse_ProjectReport\\data\\deleted_name_duplicates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db33efc1",
   "metadata": {},
   "source": [
    "Now we drop the 'Name' duplicates from the original d1_2 dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286db081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_2 = df1_2.drop_duplicates(subset='Name', keep=False)\n",
    "df1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255652df",
   "metadata": {},
   "source": [
    "Find duplicates in the 'ID' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad16036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2[df1_2.duplicated('ID', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd4e42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# duplicates = df1_2[df1_2.duplicated(subset=['ID', 'Name'], keep=False)]\n",
    "# id_duplicates = df1_2[df1_2.duplicated('ID', keep = False)]\n",
    "id_duplicates = df1_2[df1_2.duplicated('ID', keep = 'first')]\n",
    "id_duplicates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69b385",
   "metadata": {},
   "source": [
    "For duplicates found in the column ID, generate 3-digit numbers to replace each duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in id_duplicates.iterrows():\n",
    "    new_id = np.random.randint(100, 1000)  # Generate a random 3-digit number\n",
    "    while new_id in df1_2['ID'].values:  # Ensure uniqueness against entire 'ID' column\n",
    "        new_id = np.random.randint(100, 1000)\n",
    "    df1_2.at[index, 'ID'] = new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40cb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62a954",
   "metadata": {},
   "source": [
    "Check the address column for spelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2853275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_2['Address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_spelling(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.correct()\n",
    "\n",
    "df1_2['Corrected_Address'] = df1_2['Address'].apply(check_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2['Address_Match'] = df1_2['Address'] == df1_2['Corrected_Address']\n",
    "df1_2['Address_Match']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
